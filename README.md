# Linear-Regression-Machine-Learning

## Linear Regression with Gradient Descent

<p> This Python program implements linear regression using gradient descent optimization. It takes input from two different text files, each containing initial weights and training data. The algorithm calculates predictions, errors, squared errors, and error deltas for each iteration, updating the weights after each iteration.</p>

## Key Features:

<p>Input Files: The program reads data from two input text files, each containing initial weights and training data for linear regression. </p>

<p>Gradient Descent: Implements the gradient descent algorithm to optimize the weights for linear regression. It iteratively updates the weights to minimize the cost function.</p>

<p>Error Analysis: Calculates and tracks errors, squared errors, and error deltas for each iteration, providing insights into the model's performance.</p>

<p> Normalization: Includes a function to normalize features for better convergence during gradient descent.</p>

<p> Visualization: Generates plots to visualize the cost function and track its convergence over iterations.</p>


## Usage:

<p> Ensure Python and necessary libraries (NumPy, Matplotlib) are installed.
Prepare input text files containing initial weights and training data.
Run the program, providing the input file paths.
The program computes predictions, errors, and updates weights iteratively, displaying results at each iteration.
Visualize the convergence of the cost function using generated plots. </p>

## Contributors:

<p>Lawrence Menegus</p>
